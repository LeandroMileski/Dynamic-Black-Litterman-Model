{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeandroTinoco/Dynamic-Black-Litterman-Model/blob/main/The_10y_Dynamic_Black_Litterman_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXdbiHc0AnfS",
        "outputId": "c0303094-6a65-4f02-9465-53c54d03dff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.52)\n",
            "Collecting PyPortfolioOpt\n",
            "  Downloading pyportfolioopt-1.5.6-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.3.1)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: cvxpy>=1.1.19 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (1.6.0)\n",
            "Collecting ecos<3.0.0,>=2.0.14 (from PyPortfolioOpt)\n",
            "  Downloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (5.24.1)\n",
            "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (1.13.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (0.6.7.post3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (0.10.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (3.2.7.post2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib>=1.1->yfinance) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly<6.0.0,>=5.0.0->PyPortfolioOpt) (9.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (0.1.7.post5)\n",
            "Downloading pyportfolioopt-1.5.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.1/220.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ecos, PyPortfolioOpt\n",
            "Successfully installed PyPortfolioOpt-1.5.6 ecos-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy matplotlib yfinance PyPortfolioOpt\n",
        "import os\n",
        "if not os.path.isdir('data'):\n",
        "    os.system('git clone https://github.com/robertmartin8/PyPortfolioOpt.git')\n",
        "    os.chdir('PyPortfolioOpt/cookbook')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyfiglet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxUiKesvrBvU",
        "outputId": "6fae515e-83c6-43d7-94f8-6ab26b9ad0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyfiglet\n",
            "  Downloading pyfiglet-1.0.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading pyfiglet-1.0.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyfiglet\n",
            "Successfully installed pyfiglet-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tabulate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPxboaIuotJ4",
        "outputId": "b7ef9b7d-80c2-4067-922a-927a24eb0bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs5cBlLfAbNf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from pandas_datareader import data as pdr\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "from pypfopt import EfficientFrontier, objective_functions\n",
        "from pypfopt.plotting import plot_weights\n",
        "import plotly.express as px\n",
        "import pypfopt\n",
        "pypfopt.__version__\n",
        "from pypfopt import black_litterman, risk_models, expected_returns\n",
        "from pypfopt import BlackLittermanModel, plotting\n",
        "from pypfopt.plotting import plot_weights\n",
        "import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from datetime import datetime, timedelta\n",
        "from tabulate import tabulate\n",
        "from pyfiglet import Figlet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ybill ={'2023': 4.72,\n",
        "#   '2022': 0.40,\n",
        "#   '2021': 0.10,\n",
        "#   '2020': 1.56,\n",
        "#   '2019': 2.60,\n",
        "#   '2018': 1.83,\n",
        "#   '2017': 0.81,\n",
        "#   '2016': 0.61,\n",
        "#   '2015': 0.25,\n",
        "#   '2014': 0.13,\n",
        "#   '2013': 0.15}\n",
        "\n",
        "tickers = [\"VGT\",\"VHT\",\"VFH\",\"VCR\",\"VIS\",\"VOX\",\"VDC\",\"VDE\",\"VAW\", \"VPU\", \"VNQ\"]\n",
        "estimate = [ 0.07 , 0.07 , 0.07 , 0.07 , 0.07 , 0.07 ,0.07 ,0.07 , 0.07 , 0.07 , 0.07]\n",
        "confidences = [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0]\n",
        "start_date = \"2005-01-01\"\n",
        "market_prices_all = yf.download(\"VFIAX\", start=start_date)[\"Close\"]\n",
        "sp_index_all = yf.download(\"SPY\", start=\"2005-01-01\")[\"Close\"]\n",
        "\n",
        "ohlc = yf.download(tickers, start=start_date)\n",
        "#risk_free_rate = yf.download(\"^TNX\", start=start_date)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l4JJujKL20t",
        "outputId": "bc4d934e-ba1c-4024-ba84-58e484e49be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  11 of 11 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghoX_hFkAbNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154d2e21-2386-439b-9e4b-8ddebdcda74c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-32a58b3dcc42>:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  intervals.append([lb[i], ub[i]])\n",
            "<ipython-input-10-32a58b3dcc42>:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  intervals.append([lb[i], ub[i]])\n",
            "<ipython-input-10-32a58b3dcc42>:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  intervals.append([lb[i], ub[i]])\n",
            "<ipython-input-10-32a58b3dcc42>:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  intervals.append([lb[i], ub[i]])\n",
            "<ipython-input-10-32a58b3dcc42>:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  intervals.append([lb[i], ub[i]])\n",
            "<ipython-input-10-32a58b3dcc42>:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  intervals.append([lb[i], ub[i]])\n",
            "<ipython-input-10-32a58b3dcc42>:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  intervals.append([lb[i], ub[i]])\n",
            "<ipython-input-10-32a58b3dcc42>:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  intervals.append([lb[i], ub[i]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  _____        _____    _  _______ _      _      ______ _____  \n",
            " / ____| ___  |  __ \\  | |/ /_   _| |    | |    |  ____|  __ \\ \n",
            "| (___  ( _ ) | |__) | | ' /  | | | |    | |    | |__  | |__) |\n",
            " \\___ \\ / _ \\/\\  ___/  |  <   | | | |    | |    |  __| |  _  / \n",
            " ____) | (_>  < |      | . \\ _| |_| |____| |____| |____| | \\ \\ \n",
            "|_____/ \\___/\\/_|      |_|\\_\\_____|______|______|______|_|  \\_\\\n",
            "                                                               \n",
            "                                                               \n",
            " _             _        __  __ _ _           _    _  \n",
            "| |           | |      |  \\/  (_) |         | |  (_) \n",
            "| |__  _   _  | |      | \\  / |_| | ___  ___| | ___  \n",
            "| '_ \\| | | | | |      | |\\/| | | |/ _ \\/ __| |/ / | \n",
            "| |_) | |_| | | |____ _| |  | | | |  __/\\__ \\   <| | \n",
            "|_.__/ \\__, | |______(_)_|  |_|_|_|\\___||___/_|\\_\\_| \n",
            "        __/ |                                        \n",
            "       |___/                                         \n",
            "\n",
            "+--------------+-------+------+------+------+------+\n",
            "| CUMULATIVE   | 10y   | 7y   | 5y   | 3y   | 1y   |\n",
            "+==============+=======+======+======+======+======+\n",
            "| LongShort    | 344%  | 216% | 181% | 59%  | 49%  |\n",
            "+--------------+-------+------+------+------+------+\n",
            "| maxSharpe    | 327%  | 201% | 139% | 42%  | 25%  |\n",
            "+--------------+-------+------+------+------+------+\n",
            "| Benchmark    | 238%  | 147% | 98%  | 30%  | 26%  |\n",
            "+--------------+-------+------+------+------+------+\n",
            "+-----------+-----------+--------+---------+\n",
            "| 10YEARS   | AVERAGE   | BEST   | WORST   |\n",
            "+===========+===========+========+=========+\n",
            "| longShort | 19%       | 50%    | -29%    |\n",
            "+-----------+-----------+--------+---------+\n",
            "| maxSharpe | 17%       | 40%    | -19%    |\n",
            "+-----------+-----------+--------+---------+\n",
            "| benchMark | 14%       | 31%    | -18%    |\n",
            "+-----------+-----------+--------+---------+\n",
            "+--------+-------------+------------+-------------+\n",
            "|   Year | LongShort   | MaxSharp   | BenchMark   |\n",
            "+========+=============+============+=============+\n",
            "|   2015 | 1%          | 2%         | 1%          |\n",
            "+--------+-------------+------------+-------------+\n",
            "|   2016 | 14%         | 14%        | 12%         |\n",
            "+--------+-------------+------------+-------------+\n",
            "|   2017 | 22%         | 22%        | 21%         |\n",
            "+--------+-------------+------------+-------------+\n",
            "|   2018 | -18%        | -7%        | -5%         |\n",
            "+--------+-------------+------------+-------------+\n",
            "|   2019 | 37%         | 36%        | 31%         |\n",
            "+--------+-------------+------------+-------------+\n",
            "|   2020 | 34%         | 28%        | 18%         |\n",
            "+--------+-------------+------------+-------------+\n",
            "|   2021 | 32%         | 31%        | 29%         |\n",
            "+--------+-------------+------------+-------------+\n",
            "|   2022 | -29%        | -19%       | -18%        |\n",
            "+--------+-------------+------------+-------------+\n",
            "|   2023 | 50%         | 40%        | 27%         |\n",
            "+--------+-------------+------------+-------------+\n",
            "|   2024 | 49%         | 25%        | 26%         |\n",
            "+--------+-------------+------------+-------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-32a58b3dcc42>:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  intervals.append([lb[i], ub[i]])\n",
            "<ipython-input-10-32a58b3dcc42>:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  intervals.append([lb[i], ub[i]])\n"
          ]
        }
      ],
      "source": [
        "#for the final print loop\n",
        "years = []\n",
        "longshort_values = []\n",
        "maxsharp_values = []\n",
        "benchmark_values = []\n",
        "\n",
        "\n",
        "end_date = \"2013-12-31\"\n",
        "format_string = \"%Y-%m-%d\"\n",
        "start_date = \"2005-01-01\"\n",
        "  # Open our new sheet and add some data.\n",
        "#worksheet = gc.open(spredsheet_name).sheet1\n",
        "result_1 = []\n",
        "result_2 = []\n",
        "bench = []\n",
        "ret_1 = []\n",
        "ret_2 = []\n",
        "# Loop to add 1 year for 10 times\n",
        "for _ in range(10):\n",
        "  # Convert the end_date string to a datetime object\n",
        "  end_date_dt = datetime.strptime(end_date, format_string)\n",
        "\n",
        "  # Add 1 year to the datetime object\n",
        "  end_date_dt += relativedelta(years = 1)  # Assuming a year has 365 days\n",
        "\n",
        "  # Convert the datetime object back to a string\n",
        "  end_date = end_date_dt.strftime(format_string)\n",
        "\n",
        "  # Convert the end_date string to a datetime object\n",
        "  start_date_dt = datetime.strptime(end_date, format_string)\n",
        "\n",
        "  # Add 1 year to the datetime object\n",
        "  start_date_dt -= relativedelta(years = 4)  # Assuming a year has 365 days\n",
        "\n",
        "  # Convert the datetime object back to a string\n",
        "  start_date_market = start_date_dt.strftime(format_string)\n",
        "\n",
        "  prices = ohlc[\"Close\"][(start_date):(end_date)]\n",
        "  market_prices = market_prices_all[(start_date_market):(end_date)]\n",
        "  mcaps_percent = [28.39 , 13.23 , 12.2 , 10.86 , 8.96 , 8.381 , 6.44 , 4.09 , 2.52 ,2.48 , 2.46]\n",
        "  mcaps = {}\n",
        "  counter = 0\n",
        "  for t in tickers:\n",
        "    stock = yf.Ticker(t)\n",
        "    mcaps[t] = mcaps_percent[counter] * 1000000\n",
        "    counter += 1\n",
        "\n",
        "  #S = risk_models.CovarianceShrinkage(prices).ledoit_wolf(shrinkage_target='single_factor')\n",
        "  #S = risk_models.CovarianceShrinkage(prices).ledoit_wolf()\n",
        "  S = pypfopt.risk_models.risk_matrix(prices, method='exp_cov')\n",
        "  #mu = expected_returns.mean_historical_return(prices)\n",
        "  delta = black_litterman.market_implied_risk_aversion(market_prices)\n",
        "  market_prior = black_litterman.market_implied_prior_returns(mcaps, delta, S,risk_free_rate=0.022)\n",
        "\n",
        "  estimate = estimate\n",
        "  viewdict = {}\n",
        "  counter = 0\n",
        "  for t in tickers:\n",
        "    stock = yf.Ticker(t)\n",
        "    viewdict[t] = estimate[counter]\n",
        "    counter += 1\n",
        "\n",
        "  bl = BlackLittermanModel(S, pi=market_prior, absolute_views=viewdict)\n",
        "\n",
        "  confidences = confidences\n",
        "\n",
        "  bl = BlackLittermanModel(S, pi=market_prior, absolute_views=viewdict, omega=\"idzorek\", view_confidences=confidences)\n",
        "\n",
        "  lb = prices.mean() - prices.std()\n",
        "  ub = prices.mean() + prices.std()\n",
        "\n",
        "  intervals = []\n",
        "  for i in range(len(lb)):\n",
        "      intervals.append([lb[i], ub[i]])\n",
        "\n",
        "      variances = []\n",
        "  for lb, ub in intervals:\n",
        "      sigma = (ub - lb)/2\n",
        "      variances.append(sigma ** 2)\n",
        "\n",
        "  omega = np.diag(variances)\n",
        "\n",
        "  bl = BlackLittermanModel(S, pi=\"market\", market_caps=mcaps, risk_aversion=delta,\n",
        "                          absolute_views=viewdict, omega=omega)\n",
        "\n",
        "  ret_bl = bl.bl_returns()\n",
        "\n",
        "  rets_df = pd.DataFrame([market_prior, ret_bl, pd.Series(viewdict)],\n",
        "              index=[\"Prior\", \"Posterior\", \"Views\"]).T\n",
        "\n",
        "  S_bl = bl.bl_cov()\n",
        "\n",
        "  #Maximum Sharpe (No shorts allowed)\n",
        "  ef = EfficientFrontier(ret_bl, S_bl, weight_bounds=(0,1))\n",
        "  raw_weights_maxsharpe_exp = ef.max_sharpe(risk_free_rate=0.02)\n",
        "  weights = ef.clean_weights()\n",
        "  # pd.Series(weights).plot.pie(figsize=(4,4));\n",
        "  #ef.portfolio_performance(verbose=True)\n",
        "\n",
        "  #Max Sharpe with Shorts Allowed (Long Short)\n",
        "  ef = EfficientFrontier(ret_bl, S_bl, weight_bounds=(-1,1))\n",
        "  raw_weights_minvol_exp = ef.max_sharpe(risk_free_rate=0.02)\n",
        "  weights = ef.clean_weights()\n",
        "  # plot_weights(weights)\n",
        "  #ef.portfolio_performance(verbose=True)\n",
        "\n",
        "  # Convert the date string to a datetime object\n",
        "\n",
        "  inicial_test_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "\n",
        "  # Add 2 days to the initial date\n",
        "  inicial_test_date = inicial_test_date + timedelta(days=1)\n",
        "\n",
        "  # Convert the new date back to a string\n",
        "  inicial_test_date_string = inicial_test_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "  # Convert the date string to a datetime object\n",
        "\n",
        "  end_test_date = datetime.strptime(inicial_test_date_string, \"%Y-%m-%d\")\n",
        "\n",
        "  # Add 1 year to the initial date\n",
        "  end_test_date = end_test_date + relativedelta(years = 1)\n",
        "\n",
        "  # Convert the new date back to a string\n",
        "  end_test_date_string = end_test_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "  #portfolio_returns= yf.download(tickers, start=(end_date))[\"Close\"].pct_change().dropna()\n",
        "  portfolio_returns= ohlc[\"Close\"][(end_date):].pct_change().dropna()\n",
        "  test = portfolio_returns[(inicial_test_date_string):(end_test_date)]\n",
        "\n",
        "  #sp_index_all = yf.download(\"SPY\", start=end_date, end=end_test_date)[\"Close\"].pct_change().dropna()\n",
        "  sp_index = sp_index_all[(end_date):(end_test_date)].pct_change().dropna()\n",
        "\n",
        "  weights_minvol_exp = list(raw_weights_minvol_exp.values())\n",
        "  weights_maxsharpe_exp = list(raw_weights_maxsharpe_exp.values())\n",
        "\n",
        "  ret_1 = test.dot(weights_minvol_exp).add(1).cumprod()#.subtract(1).multiply(100)\n",
        "  ret_2 = test.dot(weights_maxsharpe_exp).add(1).cumprod()#.subtract(1).multiply(100)\n",
        "  ind_ret =  sp_index[(inicial_test_date_string):(end_test_date)].add(1).cumprod()#.subtract(1).multiply(100)\n",
        "  #ind_ret.name = 'Benchmark (S&P500)'\n",
        "\n",
        "\n",
        "\n",
        "  # print(\"last training date:\", end_date)\n",
        "  # print(\"last test date:\", end_test_date_string)\n",
        "  # print(inicial_test_date.year)\n",
        "  # print(\"LongShort:\", round(ret_1.iloc[-1], 2))\n",
        "  # print(\"MaxSharp:\", round(ret_2.iloc[-1], 2))\n",
        "  # print(\"BENCHMARK:\", round(ind_ret.iloc[-1], 2))\n",
        "  # print()\n",
        "\n",
        "\n",
        "\n",
        "  years.append(inicial_test_date.year)\n",
        "  longshort_values.append(round(ret_1.iloc[-1], 2))\n",
        "  maxsharp_values.append(round(ret_2.iloc[-1], 2))\n",
        "  benchmark_values.append(round(ind_ret.iloc[-1], 2))\n",
        "\n",
        "\n",
        "  result_1.append(ret_1.iloc[-1])\n",
        "  result_2.append(ret_2.iloc[-1])\n",
        "  bench.append(ind_ret.iloc[-1])\n",
        "##LOOP END\n",
        "\n",
        "custom_figlet = Figlet(font='big',width=70)  # You can choose a different font style\n",
        "#custom_figlet_sub = Figlet(font='smslant', width =70)\n",
        "logo_name = \"S&P KILLER by L.Mileski \"\n",
        "#sub = \"\"\n",
        "ascii_art = custom_figlet.renderText(logo_name)\n",
        "#ascii_art_sub = custom_figlet_sub.renderText(sub)\n",
        "\n",
        "print(ascii_art)\n",
        "#print(ascii_art_sub)\n",
        "\n",
        "\n",
        "\n",
        "data_matrix_compound = []\n",
        "\n",
        "# Collect data for each row\n",
        "data_matrix_compound.append([\"LongShort\",\n",
        "                             f\"{round(np.prod(result_1) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(result_1[-7:]) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(result_1[-5:]) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(result_1[-3:]) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(result_1[-1]) * 100) - 100}%\"])\n",
        "\n",
        "data_matrix_compound.append([\"maxSharpe\",\n",
        "                             f\"{round(np.prod(result_2) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(result_2[-7:]) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(result_2[-5:]) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(result_2[-3:]) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(result_2[-1]) * 100) - 100}%\"])\n",
        "\n",
        "data_matrix_compound.append([\"Benchmark\",\n",
        "                             f\"{round(np.prod(bench) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(bench[-7:]) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(bench[-5:]) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(bench[-3:]) * 100) - 100}%\",\n",
        "                             f\"{round(np.prod(bench[-1]) * 100) - 100}%\"])\n",
        "\n",
        "\n",
        "headers = [\"CUMULATIVE\", \"10y\", \"7y\", \"5y\", \"3y\", \"1y\"]\n",
        "print(tabulate(data_matrix_compound, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "# print(\"          AVERAGE\")\n",
        "# print(\"LongShort:\",\n",
        "#       round(np.mean(result_1), 2))\n",
        "\n",
        "# print(\"maxSharpe:\",\n",
        "#       round(np.mean(result_2), 2))\n",
        "\n",
        "# print(\"      Spy:\",\n",
        "#       round(np.mean(bench), 2))\n",
        "\n",
        "data_matrix_average = []\n",
        "\n",
        "# Convert values to percentages by multiplying by 100\n",
        "longshort_mean_pct = round(np.mean(result_1) * 100, 2)-100\n",
        "longshort_max_pct = round(np.max(result_1) * 100, 2)-100\n",
        "longshort_min_pct = round(np.min(result_1) * 100, 2)-100\n",
        "\n",
        "maxsharp_mean_pct = round(np.mean(result_2) * 100, 2)-100\n",
        "maxsharp_max_pct = round(np.max(result_2) * 100, 2)-100\n",
        "maxsharp_min_pct = round(np.min(result_2) * 100, 2)-100\n",
        "\n",
        "bench_mean_pct = round(np.mean(bench) * 100, 2)-100\n",
        "bench_max_pct = round(np.max(bench) * 100, 2)-100\n",
        "bench_min_pct = round(np.min(bench) * 100, 2)-100\n",
        "\n",
        "data_matrix_average.append([\"longShort\",\n",
        "                            f\"{longshort_mean_pct:.0f}%\",\n",
        "                            f\"{longshort_max_pct:.0f}%\",\n",
        "                            f\"{longshort_min_pct:.0f}%\"])\n",
        "\n",
        "data_matrix_average.append([\"maxSharpe\",\n",
        "                            f\"{maxsharp_mean_pct:.0f}%\",\n",
        "                            f\"{maxsharp_max_pct:.0f}%\",\n",
        "                            f\"{maxsharp_min_pct:.0f}%\"])\n",
        "\n",
        "data_matrix_average.append([\"benchMark\",\n",
        "                            f\"{bench_mean_pct:.0f}%\",\n",
        "                            f\"{bench_max_pct:.0f}%\",\n",
        "                            f\"{bench_min_pct:.0f}%\"])\n",
        "\n",
        "\n",
        "headers = [\"10YEARS\", \"AVERAGE\", \"BEST\", \"WORST\"]\n",
        "\n",
        "print(tabulate(data_matrix_average, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "# Separate loop for printing\n",
        "\n",
        "\n",
        "\n",
        "data_matrix = []\n",
        "for year, longshort, maxsharp, benchmark in zip(years, longshort_values, maxsharp_values, benchmark_values):\n",
        "    # Access the numeric value from the Series using .item() if it's a single-element Series\n",
        "    # or .iloc[-1] for the last element, or .values[0] for the first element.\n",
        "    benchmark_value = benchmark.item() if isinstance(benchmark, pd.Series) and len(benchmark) == 1 else benchmark\n",
        "    data_matrix.append([year, f\"{longshort * 100 -100:.0f}%\", f\"{maxsharp * 100 -100:.0f}%\", f\"{benchmark_value * 100 - 100:.0f}%\"])\n",
        "\n",
        "headers = [\"Year\", \"LongShort\", \"MaxSharp\", \"BenchMark\"]\n",
        "\n",
        "print(tabulate(data_matrix, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Your returns data\n",
        "data = [\n",
        "    [\"Year\", \"LongShort\", \"MaxSharp\", \"BenchMark\"],\n",
        "    [2015, \"1%\", \"2%\", \"1%\"],\n",
        "    [2016, \"14%\", \"14%\", \"12%\"],\n",
        "    [2017, \"22%\", \"22%\", \"21%\"],\n",
        "    [2018, \"-18%\", \"-7%\", \"-5%\"],\n",
        "    [2019, \"37%\", \"36%\", \"31%\"],\n",
        "    [2020, \"34%\", \"28%\", \"18%\"],\n",
        "    [2021, \"32%\", \"31%\", \"29%\"],\n",
        "    [2022, \"-29%\", \"-19%\", \"-18%\"],\n",
        "    [2023, \"50%\", \"40%\", \"27%\"],\n",
        "    [2024, \"49%\", \"25%\", \"26%\"],\n",
        "]\n",
        "\n",
        "# Create a Pandas DataFrame\n",
        "df = pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "# Convert percentage strings to numeric values\n",
        "for col in [\"LongShort\", \"MaxSharp\", \"BenchMark\"]:\n",
        "    df[col] = df[col].str.rstrip('%').astype('float') / 100\n",
        "\n",
        "# Risk-free rate (you'll need to define this)\n",
        "risk_free_rate = 0.02\n",
        "\n",
        "# --- Calculations ---\n",
        "\n",
        "def calculate_var(returns, confidence_level=0.95):\n",
        "    \"\"\"Calculates Value at Risk (VaR).\"\"\"\n",
        "    return np.percentile(returns, 100 * (1 - confidence_level))\n",
        "\n",
        "def calculate_sharpe_ratio(returns, risk_free_rate):\n",
        "    \"\"\"Calculates Sharpe Ratio.\"\"\"\n",
        "    excess_return = returns.mean() - risk_free_rate\n",
        "    return excess_return / returns.std()\n",
        "\n",
        "def calculate_max_drawdown(returns):\n",
        "    \"\"\"Calculates Maximum Drawdown.\"\"\"\n",
        "    cumulative_returns = (1 + returns).cumprod()\n",
        "    peak = cumulative_returns.cummax()\n",
        "    drawdown = (cumulative_returns - peak) / peak\n",
        "    return drawdown.min()\n",
        "\n",
        "## Calculate risk measures for each portfolio\n",
        "for portfolio in [\"LongShort\", \"MaxSharp\", \"BenchMark\"]:\n",
        "    returns = df[portfolio]\n",
        "\n",
        "    var = calculate_var(returns)\n",
        "    sharpe_ratio = calculate_sharpe_ratio(returns, risk_free_rate)\n",
        "    max_drawdown = calculate_max_drawdown(returns)\n",
        "    std_dev = returns.std()  # Calculate standard deviation\n",
        "\n",
        "    print(f\"--- {portfolio} ---\")\n",
        "    print(f\"VaR (95%): {var:.4f}\")\n",
        "    print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
        "    print(f\"Maximum Drawdown: {max_drawdown:.4f}\")\n",
        "    print(f\"Standard Deviation: {std_dev:.4f}\")  # Print std_dev\n",
        "    print(\"-\" * 20)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_WKhAiIol1O",
        "outputId": "4c1a9b7b-4584-4056-9458-847b625382b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LongShort ---\n",
            "VaR (95%): -0.2405\n",
            "Sharpe Ratio: 0.6347\n",
            "Maximum Drawdown: -0.2900\n",
            "Standard Deviation: 0.2710\n",
            "--------------------\n",
            "--- MaxSharp ---\n",
            "VaR (95%): -0.1360\n",
            "Sharpe Ratio: 0.7818\n",
            "Maximum Drawdown: -0.1900\n",
            "Standard Deviation: 0.1944\n",
            "--------------------\n",
            "--- BenchMark ---\n",
            "VaR (95%): -0.1215\n",
            "Sharpe Ratio: 0.7395\n",
            "Maximum Drawdown: -0.1800\n",
            "Standard Deviation: 0.1650\n",
            "--------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}